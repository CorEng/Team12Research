{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_test_frame(zone, row_num = 50000):\n",
    "    #Import\n",
    "    import pickle\n",
    "    import mysql.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pandas import DataFrame\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.svm import SVR\n",
    "    import mysql.connector\n",
    "    import os\n",
    "    import requests as r\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    \n",
    "    #Load models\n",
    "    target_scaler = 'tar_scaler_{0}.sav'.format(zone)\n",
    "    feature_scaler = 'feat_scaler_{0}.sav'.format(zone)\n",
    "    model = \"model_zone_{0}.sav\".format(zone)\n",
    "\n",
    "    tar_scaler = pickle.load(open(target_scaler, 'rb'))\n",
    "    feat_scaler = pickle.load(open(feature_scaler, 'rb'))\n",
    "    model = pickle.load(open(model, 'rb'))\n",
    "    \n",
    "    \n",
    "    #Open sql\n",
    "    val_list = []\n",
    "    validator = open(\"validation.txt\", \"r\")\n",
    "    for line in validator:\n",
    "        val_list.append(line.rstrip())\n",
    "\n",
    "    mydb = mysql.connector.connect(\n",
    "      host=val_list[0],\n",
    "      user=val_list[1],\n",
    "      passwd=val_list[2],\n",
    "      database=val_list[3],\n",
    "      port=val_list[4]\n",
    "    )\n",
    "    print(\"Receiving number interval for zone {0}\".format(zone))\n",
    "        \n",
    "    mycursor = mydb.cursor()\n",
    "    sql = \"\"\"SELECT COUNT(*) as nr FROM team12dublinbus.final where zone = \"\"\" +str(zone)+\"\"\";\"\"\"\n",
    "    mycursor.execute(sql)\n",
    "    result_list = []\n",
    "    rand_no = 0\n",
    "    for (r) in mycursor:\n",
    "        rand_no = str(round(row_num/int(r[0]), 4))\n",
    "\n",
    "    print(\"Received number interval from DB for zone {0}\".format(zone))\n",
    "    print(\"Receiving dataframe for zone {0}\".format(zone))\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "    sql = \"\"\"SELECT `time_to_sec(m.hr_time)`,travel_time,precipIntensity,temperature,humidity,dist,holiday,weekend \n",
    "    FROM team12dublinbus.final\n",
    "    WHERE zone = \"\"\"+str(zone)+\"\"\" and RAND() < \"\"\"+str(rand_no)+\"\"\";\"\"\"\n",
    "    mycursor.execute(sql)\n",
    "\n",
    "    print(\"Received dataframe for zone {0}. Processing frame...\".format(zone))\n",
    "\n",
    "    result_list = []\n",
    "    for (l) in mycursor:\n",
    "        result_list.extend([l])\n",
    "\n",
    "    frame = DataFrame.from_records(result_list)\n",
    "    frame.columns = ['time_of_day', 'time','precipIntensity', 'temperature', 'humidity', 'distance','holiday','weekend']\n",
    "    \n",
    "    print(\"Frame processed. Starting data scaling\")\n",
    "    X= frame[['time_of_day','precipIntensity', 'temperature', 'humidity', 'distance','holiday','weekend']]\n",
    "    Y = frame[['time']]\n",
    "\n",
    "    X = feat_scaler.transform(X[['time_of_day','precipIntensity', 'temperature', 'humidity', 'distance','holiday','weekend']])         \n",
    "    Y = tar_scaler.transform(Y[['time']])  \n",
    "    \n",
    "    print(\"Frames scaled. Starting model prediction\")\n",
    "    predicted = model.predict(X)\n",
    "    \n",
    "    print(\"Starting metric check\")\n",
    "    result = metrics.mean_squared_error(Y,predicted)\n",
    "    \n",
    "    result = tar_scaler.inverse_transform(pd.array([1,result]))\n",
    "    \n",
    "    print(\"Completed test for zone {0}. Returning RMSE\".format(zone))\n",
    "    return np.sqrt(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving number interval for zone 6\n",
      "Received number interval from DB for zone 6\n",
      "Receiving dataframe for zone 6\n",
      "Received dataframe for zone 6. Processing frame...\n",
      "Frame processed. Starting data scaling\n",
      "Frames scaled. Starting model prediction\n",
      "Starting metric check\n",
      "Completed test for zone 6. Returning RMSE\n",
      "12.377194614974622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\env\\lib\\site-packages\\ipykernel_launcher.py:71: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "E:\\Anaconda\\envs\\env\\lib\\site-packages\\ipykernel_launcher.py:72: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "print(return_test_frame(6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
